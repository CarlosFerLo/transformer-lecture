{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers in Pytorch\n",
    "\n",
    "The idea of this notebook is to explain how transformers are coded in pytorch. We will take as reference the original [Attention is all you need](https://arxiv.org/abs/1706.03762) paper and this [video](https://www.youtube.com/watch?v=ISNdQcPhsts). The transformer we are going to build is rather simple and it will translate sentences from English to Spanish.\n",
    "\n",
    "First we will build the transformer component by component and then we will work on the training loop and inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Transformer\n",
    "\n",
    "In order to build the transformer, we will have to build all the inner components first. The base components of the transformer are:\n",
    "- Input Embeddings\n",
    "- Positional Encoding\n",
    "- Layer Normalization\n",
    "- Feed Forward Block\n",
    "- Multi Head Attention Block\n",
    "\n",
    "Then we have the encoder and the decoder, both composed of many encoder and decoder blocks. And finally a projection layer.\n",
    "\n",
    "![Transformer Architecture](assets/transformer-network.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Embeddings\n",
    "This layer will assign a vector to each of the tokens of the input sequence. This vectors are learned during training and represent the \"meaning\" of the token (or word). \n",
    "\n",
    "A `nn.Module` with this functionality already exists in PyTorch, but we will build a module on top in order to make reference to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEmbedding (nn.Module) :\n",
    "    \n",
    "    def __init__(self, d_model: int, vocab_size: int) -> None :\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        \n",
    "    def forward (self, x) :\n",
    "        return self.embedding(x) * math.sqrt(self.d_model) # as specified in the original paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional Encoding\n",
    "\n",
    "The Positional Encodings adds some vectors to the embeddings in order to encode the position of the token in the sentence (e.g. first, second, ...). There are many ways to archive this, but here we will use the vectors proposed in the original paper, calculated with the following functions:\n",
    "\n",
    "![Positional Encodings Functions](assets/positional-encoding-functions.png)\n",
    "\n",
    "Where $pos$ is the position of the token in the sentence and $i$ is the dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module) :\n",
    "    \n",
    "    def __init__(self, d_model: int, seq_len: int, dropout: float) -> None :\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.seq_len = seq_len\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        pe = torch.zeros(seq_len, d_model) # (seq_len, d_model)\n",
    "        \n",
    "        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1) # (seq_len)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(1000) / d_model)) # more numerically stable\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        pe = pe.unsqueeze(0) # (1, seq_len, d_model)\n",
    "        \n",
    "        self.register_buffer(\"pe\", pe) # Save it to the state file, but not as a parameter\n",
    "        \n",
    "    def forward (self, x) :\n",
    "        x = x + (self.pe[:, :x.shape[1], :]).requires_grad_(False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Normalization\n",
    "\n",
    "This component normalizes each input (each vector corresponding to a token) so its values have mean 0 and variance 1. Then it scales the values with a parameter $\\alpha$ and shifts them with a parameter $\\beta$.\n",
    "\n",
    "The propose of this block is to stabilize and accelerate the training of the model as inputs of the next block will be on a specified range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(nn.Module) :\n",
    "    \n",
    "    def __init__(self, eps: float = 10**-6) -> None :\n",
    "        super().__init__()\n",
    "        self. eps = eps # numerical stability\n",
    "        \n",
    "        self.alpha = nn.Parameter(torch.ones(1)) # Multiplied \n",
    "        self.beta = nn.Parameter(torch.ones(1)) # Added\n",
    "        \n",
    "    def forward (self, x) :\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        std = x.std(dim=-1, keepdim=True)\n",
    "        return self.alpha * (x - mean) / (std + self.eps) + self.beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed Forward Block\n",
    "\n",
    "This block is a simple fully-connected two layer neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardBlock (nn.Module) :\n",
    "    \n",
    "    def __init__ (self, d_model: int, d_ff: int, dropout: float) -> None :\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "        \n",
    "    def forward (self, x) :\n",
    "        # (batch, seq_len, d_model) --> (batch, seq_len, d_ff) --> (batch, seq_len, d_model)\n",
    "        return self.linear_2(self.dropout(torch.relu(self.linear_1(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
